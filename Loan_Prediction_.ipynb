{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #imported pandas library\n",
    "import numpy   #imported numpy library\n",
    "y = pd.read_json('loan_data.json')   # stored load_data.json in y using pandas\n",
    "y.to_csv('lon.csv', index = False)  #created lon.csv file\n",
    "k = pd.read_csv('lon.csv')\n",
    "l = pd.DataFrame(k)      #created dataframe l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Find % of total applicants for each unique value of dependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     57.534247\n",
       "2     17.221135\n",
       "1     16.634051\n",
       "3+     8.610568\n",
       "Name: Dependents, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l['Dependents'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Find the average number of dependents per applicant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "l['Dependents'] = l['Dependents'].map({'3+': 5,'1' : 1 , '2' : 2 , '0': 0})\n",
    "#replaced 3+ by 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependents</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Application_ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>LP001002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP001003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP001005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP001006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP001008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP002978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP002979</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP002983</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP002984</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP002990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>511 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dependents\n",
       "Application_ID            \n",
       "LP001002                 0\n",
       "LP001003                 1\n",
       "LP001005                 0\n",
       "LP001006                 0\n",
       "LP001008                 0\n",
       "...                    ...\n",
       "LP002978                 0\n",
       "LP002979                 5\n",
       "LP002983                 1\n",
       "LP002984                 2\n",
       "LP002990                 0\n",
       "\n",
       "[511 rows x 1 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.groupby('Application_ID').agg({ 'Dependents': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Find the %of applications approved for self employed applicants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.698630136986301"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(l[l['Self_Employed'] == 'Yes']['Self_Employed'].count()/len(l))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) What is the % of rejections for married male applicants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.025440313111545"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[(l['Married'] == 'Yes') & (l['Gender'] == 'Male') & (l['Application_Status'] == 'N')]['Application_Status'].count()/len(l)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5) Which property area has the maximum approval ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Semiurban    44.092219\n",
       "Urban        29.971182\n",
       "Rural        25.936599\n",
       "Name: Property_Area, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[l['Application_Status'] == 'Y']['Property_Area'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (6) Find average dependents per income group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependents</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>high</td>\n",
       "      <td>1.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>low</td>\n",
       "      <td>0.765568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>medium</td>\n",
       "      <td>1.150259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dependents\n",
       "Income            \n",
       "high      1.111111\n",
       "low       0.765568\n",
       "medium    1.150259"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.groupby('Income').agg({ 'Dependents': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  (7) Create a simple predictive model to assess whether a loan application will be approved or rejected and provide the accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imported Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "df = pd.read_json('loan_data.json')\n",
    "df.to_csv('loan.csv', index = False)   #loan.csv file contains all data which is present in loan_data.json \n",
    "train = pd.read_csv('loan.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#import itertools\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # we split data in train and test\n",
    "X_train,X_test=train_test_split(df,test_size=0.2) # training set is 80% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('train_loanprediction.csv', index = False)  #X_train is stored in train_loanprediction.csv\n",
    "X_test.to_csv('test_loanprediction.csv', index = False)  #X_test is stored in test_loanprediction.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_loanprediction.csv') #uesd pandas library to read data\n",
    "test = pd.read_csv('test_loanprediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we have to check whether the data is cleaned or not. And after cleaning part, we have to structure the Data. For cleaning part, First I have to check whether there exists any missing values. For that I am using the code snippet isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Application_ID        0\n",
       "Gender                0\n",
       "Married               0\n",
       "Dependents            0\n",
       "Education             0\n",
       "Self_Employed         0\n",
       "Credit_History        0\n",
       "Property_Area         0\n",
       "Income                0\n",
       "Application_Status    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loan_ID should be unique. So if there n number of rows, there should be n number of unique Loan_ID’s. Let us check for that. If there are any duplicate values we can remove that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Application_ID        383\n",
       "Gender                  2\n",
       "Married                 2\n",
       "Dependents              4\n",
       "Education               2\n",
       "Self_Employed           2\n",
       "Credit_History          2\n",
       "Property_Area           3\n",
       "Income                  3\n",
       "Application_Status      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are 383 rows in our train data set, there should be 383 unique Loan_ID’s. Fortunately there are no duplicate values. We can also see that for Gender, Married, Education and Self_Employed columns, the values are only 2 which is evident after cleaning the data-set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our target variable is Loan_Status. We are storing it in a variable called y. But before doing all these we are dropping Application_ID column in both the data sets. Here it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train.drop('Application_ID', axis = 1)\n",
    "test2 = test.drop('Application_ID', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train2.drop('Application_Status',1) #dropped Application_Status column\n",
    "y = train2.Application_Status       #stored Application_status in y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383, 8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    N\n",
       "1    N\n",
       "2    Y\n",
       "3    Y\n",
       "4    Y\n",
       "Name: Application_Status, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to convert every categorical variable in to numerical, I have used get_dummies method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converted categorical variables into 0 and 1\n",
    "X = pd.get_dummies(X)\n",
    "train2 = pd.get_dummies(train2)\n",
    "test2 = pd.get_dummies(test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X contains all columns except Application_ID and Application_Status column\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to run a gradient boosted classifier over our data. \n",
    "#Note numerous different values were used in the param_grid to hone in on the best paramater\n",
    "#combinations. The param grid below is the final one I used\n",
    "def model(X_train, X_val, y_train, y_val):\n",
    "    if __name__ == '__main__':\n",
    "    \n",
    "        param_grid = {'learning_rate': [0.03, 0.035],\n",
    "                      'max_depth': [3, 4, 5],\n",
    "                      'min_samples_leaf': [17, 18],\n",
    "                      'max_features': [1.0, 0.95, 0.9],\n",
    "                      'n_estimators': [100, 300, 500]\n",
    "                      }\n",
    "\n",
    "        estimator = GridSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                                 param_grid=param_grid,\n",
    "                                 n_jobs=-1)\n",
    "\n",
    "        estimator.fit(X_train, y_train)\n",
    "\n",
    "        best_params = estimator.best_params_\n",
    "                                 \n",
    "        validation_accuracy = estimator.score(X_val, y_val)\n",
    "        print('Validation accuracy: ', validation_accuracy)\n",
    "        #print(validation_accuracy*100)\n",
    "        return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'min_samples_leaf': 17, 'max_features': 0.95, 'max_depth': 3,\n",
    "          'learning_rate': 0.03, 'n_estimators': 500}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.03, loss='deviance', max_depth=3,\n",
       "                           max_features=0.95, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=17, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(**params)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test2.drop('Application_Status_N', axis = 1)\n",
    "test2 = test2.drop('Application_Status_Y', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = test['Application_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.Series(preds)\n",
    "submit = pd.concat([submit, preds], names=['Application_ID', 'Application_Status'], axis=1)\n",
    "submit.columns = ['Application_ID', 'Application_Status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result is storesd in result1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('result1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = pd.read_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{'C': [0,1,5], 'kernel':['linear']},\n",
    "             {'C': [0,1,5], 'kernel':['rbf'], 'gamma':[0.01, 0.05]}]\n",
    "\n",
    "\n",
    "param_grid = {'learning_rate': [0.03, 0.035],\n",
    "                      'max_depth': [3, 4, 5],\n",
    "                      'min_samples_leaf': [17, 18],\n",
    "                      'max_features': [1.0, 0.95, 0.9],\n",
    "                      'n_estimators': [100, 300, 500]\n",
    "                      }\n",
    "\n",
    "\n",
    "estimator = GridSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                                 param_grid=param_grid,\n",
    "                                 n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                  criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.1,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=None,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,\n",
       "                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                  n_estimators=100,\n",
       "                                                  n_iter_n...\n",
       "                                                  random_state=None,\n",
       "                                                  subsample=1.0, tol=0.0001,\n",
       "                                                  validation_fraction=0.1,\n",
       "                                                  verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.03, 0.035], 'max_depth': [3, 4, 5],\n",
       "                         'max_features': [1.0, 0.95, 0.9],\n",
       "                         'min_samples_leaf': [17, 18],\n",
       "                         'n_estimators': [100, 300, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = estimator.best_params_\n",
    "                                 \n",
    "validation_accuracy = estimator.score(X_val, y_val)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We Got Accuracy of 81.81%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.81818181818183"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
